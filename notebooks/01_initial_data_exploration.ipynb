{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# We set the display options to ensure we can see columns clearly later\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: File path found.\n"
     ]
    }
   ],
   "source": [
    "# Exact path provided by you\n",
    "raw_data_path = '/Users/maneeshkoti/Documents/ecommerce-churn-prediction/data/raw/online_retail_II.xlsx'\n",
    "\n",
    "# Verify the file exists before trying to load it\n",
    "if os.path.exists(raw_data_path):\n",
    "    print(\"Success: File path found.\")\n",
    "else:\n",
    "    print(f\"Error: File not found at {raw_data_path}\")\n",
    "    print(\"Please check for typos in the path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File loaded successfully.\n",
      "Sheets found in this file: ['Year 2009-2010', 'Year 2010-2011']\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the Excel file object (lighter than loading the whole dataframe)\n",
    "    xls = pd.ExcelFile(raw_data_path, engine='openpyxl')\n",
    "    \n",
    "    print(\"File loaded successfully.\")\n",
    "    print(f\"Sheets found in this file: {xls.sheet_names}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load 'Year 2009-2010'...\n",
      "Loaded 'Year 2009-2010': 525461 rows\n",
      "Attempting to load 'Year 2010-2011'...\n",
      "Loaded 'Year 2010-2011': 541910 rows\n",
      "------------------------------\n",
      "Total Rows Loaded: 1067371\n",
      "Total Columns: 8\n",
      "Column Names: ['Invoice', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'Price', 'Customer ID', 'Country']\n"
     ]
    }
   ],
   "source": [
    "# We define the standard sheet names for the Online Retail II dataset\n",
    "# We use 'try-except' blocks in case your specific Excel file has different names\n",
    "dfs = []\n",
    "\n",
    "try:\n",
    "    print(\"Attempting to load 'Year 2009-2010'...\")\n",
    "    df_09_10 = pd.read_excel(xls, sheet_name='Year 2009-2010', engine='openpyxl')\n",
    "    dfs.append(df_09_10)\n",
    "    print(f\"Loaded 'Year 2009-2010': {df_09_10.shape[0]} rows\")\n",
    "except ValueError:\n",
    "    print(\"Sheet 'Year 2009-2010' not found.\")\n",
    "\n",
    "try:\n",
    "    print(\"Attempting to load 'Year 2010-2011'...\")\n",
    "    df_10_11 = pd.read_excel(xls, sheet_name='Year 2010-2011', engine='openpyxl')\n",
    "    dfs.append(df_10_11)\n",
    "    print(f\"Loaded 'Year 2010-2011': {df_10_11.shape[0]} rows\")\n",
    "except ValueError:\n",
    "    print(\"Sheet 'Year 2010-2011' not found.\")\n",
    "\n",
    "# If specific sheet names failed, try loading the first sheet by default\n",
    "if not dfs:\n",
    "    print(\"Specific sheet names not found. Loading the first sheet...\")\n",
    "    df_default = pd.read_excel(raw_data_path, sheet_name=0, engine='openpyxl')\n",
    "    dfs.append(df_default)\n",
    "    print(f\"Loaded default sheet: {df_default.shape[0]} rows\")\n",
    "\n",
    "# Combine all loaded dataframes\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Total Rows Loaded: {df.shape[0]}\")\n",
    "print(f\"Total Columns: {df.shape[1]}\")\n",
    "print(f\"Column Names: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Data quality summary saved to: /Users/maneeshkoti/Documents/ecommerce-churn-prediction/data/raw/data_quality_summary.json\n",
      "------------------------------\n",
      "{\n",
      "    \"total_rows\": 1067371,\n",
      "    \"total_columns\": 8,\n",
      "    \"missing_values\": {\n",
      "        \"Invoice\": 0,\n",
      "        \"StockCode\": 0,\n",
      "        \"Description\": 4382,\n",
      "        \"Quantity\": 0,\n",
      "        \"InvoiceDate\": 0,\n",
      "        \"Price\": 0,\n",
      "        \"Customer ID\": 243007,\n",
      "        \"Country\": 0\n",
      "    },\n",
      "    \"duplicate_rows\": 34335,\n",
      "    \"date_range\": {\n",
      "        \"start\": \"2009-12-01\",\n",
      "        \"end\": \"2011-12-09\"\n",
      "    },\n",
      "    \"negative_quantities\": 22950,\n",
      "    \"cancelled_invoices\": 19494,\n",
      "    \"missing_customer_ids\": 243007,\n",
      "    \"missing_customer_ids_percentage\": 22.77\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 1. Ensure InvoiceDate is datetime (critical for date range check)\n",
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "\n",
    "# 2. Calculate Metrics required by the JSON schema\n",
    "total_rows = len(df)\n",
    "total_columns = len(df.columns)\n",
    "\n",
    "# Missing values per column\n",
    "missing_values = df.isnull().sum().to_dict()\n",
    "\n",
    "# Count duplicates\n",
    "duplicate_rows = df.duplicated().sum()\n",
    "\n",
    "# Date Range\n",
    "start_date = df['InvoiceDate'].min().strftime('%Y-%m-%d')\n",
    "end_date = df['InvoiceDate'].max().strftime('%Y-%m-%d')\n",
    "\n",
    "# Specific Data Quality Checks\n",
    "negative_quantities = (df['Quantity'] < 0).sum()\n",
    "cancelled_invoices = df['Invoice'].astype(str).str.startswith('C').sum()\n",
    "missing_customer_ids = df['Customer ID'].isnull().sum()\n",
    "missing_pct = (missing_customer_ids / total_rows) * 100\n",
    "\n",
    "# 3. Construct the Dictionary matching the Schema\n",
    "data_quality_summary = {\n",
    "    \"total_rows\": int(total_rows),\n",
    "    \"total_columns\": int(total_columns),\n",
    "    \"missing_values\": {k: int(v) for k, v in missing_values.items()},\n",
    "    \"duplicate_rows\": int(duplicate_rows),\n",
    "    \"date_range\": {\n",
    "        \"start\": start_date,\n",
    "        \"end\": end_date\n",
    "    },\n",
    "    \"negative_quantities\": int(negative_quantities),\n",
    "    \"cancelled_invoices\": int(cancelled_invoices),\n",
    "    \"missing_customer_ids\": int(missing_customer_ids),\n",
    "    \"missing_customer_ids_percentage\": float(round(missing_pct, 2))\n",
    "}\n",
    "\n",
    "# 4. Save to JSON file\n",
    "output_path = '/Users/maneeshkoti/Documents/ecommerce-churn-prediction/data/raw/data_quality_summary.json'\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(data_quality_summary, f, indent=4)\n",
    "\n",
    "print(f\"Success! Data quality summary saved to: {output_path}\")\n",
    "print(\"-\" * 30)\n",
    "print(json.dumps(data_quality_summary, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Standardized raw data saved to: /Users/maneeshkoti/Documents/ecommerce-churn-prediction/data/raw/online_retail_raw.csv\n",
      "Columns: ['InvoiceNo', 'StockCode', 'Description', 'Quantity', 'InvoiceDate', 'UnitPrice', 'CustomerID', 'Country']\n"
     ]
    }
   ],
   "source": [
    "# 1. Standardize Column Names (Map Excel names to Project Standard)\n",
    "df.rename(columns={\n",
    "    'Invoice': 'InvoiceNo',\n",
    "    'Price': 'UnitPrice',\n",
    "    'Customer ID': 'CustomerID'\n",
    "}, inplace=True)\n",
    "\n",
    "# 2. Save to CSV (This becomes the input for the next phase)\n",
    "output_csv_path = '/Users/maneeshkoti/Documents/ecommerce-churn-prediction/data/raw/online_retail_raw.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "print(f\"Success! Standardized raw data saved to: {output_csv_path}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
